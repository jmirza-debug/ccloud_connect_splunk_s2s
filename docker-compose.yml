---
version: '2'
services:
  connect:
    image: confluentinc/cp-kafka-connect:latest
    hostname: $CONTAINER_NAME
    container_name: $CONTAINER_NAME
    user: root
    volumes: 
      - ./files/:/tmp/
    ports:
      - "8083:8083"
      - "9997:9997"
      - "5555:5555"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: "${CLOUD_URL}"
      CONNECT_REST_ADVERTISED_HOST_NAME: ${CONTAINER_NAME}
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: S2Sconnect-group
      CONNECT_CONFIG_STORAGE_TOPIC: S2Sconnect-configs-1
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 3
      CONNECT_OFFSET_STORAGE_TOPIC: S2Sconnect-offsets-1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 3
      CONNECT_STATUS_STORAGE_TOPIC: S2Sconnect-status-1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 3
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CLASSPATH: /usr/share/java/monitoring-interceptors/monitoring-interceptors-5.5.0.jar
      CONNECT_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
      CONNECT_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components,/usr/local/connect/plugins"
      #### Added for Confluent Cloud
      CONNECT_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: https
      CONNECT_SECURITY_PROTOCOL: SASL_SSL
      CONNECT_SASL_MECHANISM: PLAIN
      CONNECT_SASL_JAAS_CONFIG: "org.apache.kafka.common.security.plain.PlainLoginModule required username='${CLOUD_TOKEN}' password='${CLOUD_SECRET}';"
      CONNECT_REQUEST_TIMEOUT_MS: 20000
      CONNECT_RETRY_BACKOFF_MS: 500
      CONNECT_PRODUCER_BOOTSTRAP_SERVERS: "${CLOUD_URL}"
      CONNECT_PRODUCER_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: https
      CONNECT_PRODUCER_SECURITY_PROTOCOL: SASL_SSL
      CONNECT_PRODUCER_SASL_MECHANISM: PLAIN
      CONNECT_PRODUCER_SASL_JAAS_CONFIG: "org.apache.kafka.common.security.plain.PlainLoginModule required username='${CLOUD_TOKEN}' password='${CLOUD_SECRET}';"
      CONNECT_PRODUCER_REQUEST_TIMEOUT_MS: 20000
      CONNECT_PRODUCER_RETRY_BACKOFF_MS: 500
      CONNECT_CONSUMER_BOOTSTRAP_SERVERS: "${CLOUD_URL}"
      CONNECT_CONSUMER_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: https
      CONNECT_CONSUMER_SECURITY_PROTOCOL: SASL_SSL
      CONNECT_CONSUMER_SASL_MECHANISM: PLAIN
      CONNECT_CONSUMER_SASL_JAAS_CONFIG: "org.apache.kafka.common.security.plain.PlainLoginModule required username='${CLOUD_TOKEN}' password='${CLOUD_SECRET}';"
      CONNECT_CONSUMER_REQUEST_TIMEOUT_MS: 20000
      CONNECT_CONSUMER_RETRY_BACKOFF_MS: 500
      CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
      # Schema Registry specific settings
      CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE: "true"
      CONNECT_KEY_CONVERTER_BASIC_AUTH_CREDENTIALS_SOURCE: USER_INFO
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO: ${SCHEMA_REGISTRY_BASIC_AUTH}
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: ${SCHEMA_REGISTRY_URL}
      CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "true"
      CONNECT_VALUE_CONVERTER_BASIC_AUTH_CREDENTIALS_SOURCE: USER_INFO
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO: ${SCHEMA_REGISTRY_BASIC_AUTH}
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: ${SCHEMA_REGISTRY_URL}
      CONNECT_REPORTER_ADMIN_BOOTSTRAP_SERVERS: ${CLOUD_URL}
      CONNECT_REPORTER_ADMIN_SECURITY_PROTOCOL: SASL_SSL
      CONNECT_REPORTER_ADMIN_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: https
      CONNECT_REPORTER_ADMIN_SASL_MECHANISM: PLAIN
      CONNECT_REPORTER_ADMIN_SASL_JAAS_CONFIG: "org.apache.kafka.common.security.plain.PlainLoginModule required username='${CLOUD_TOKEN}' password='${CLOUD_SECRET}';"
    command:
      - bash 
      - -c 
      - |
        echo "Installing connector plugins"
        confluent-hub install --no-prompt confluentinc/kafka-connect-splunk-s2s:latest
        #
        echo "Launching Kafka Connect worker"
        /etc/confluent/docker/run & 
        #
        sleep infinity
      - sh -c "/tmp/submit_splunk_s2s.sh"


  splunk_uf1:
    image: splunk/universalforwarder:8.2.1
    hostname: splunk_uf1
    container_name: splunk_uf1
    depends_on:
      - connect
    environment:
      - SPLUNK_START_ARGS=--accept-license
      - SPLUNK_PASSWORD=Password1
      - SPLUNK_APPS_URL=https://raw.githubusercontent.com/JohnnyMirza/confluent_splunk_demo/main/splunk-add-on-for-cisco-asa_410.tgz
    volumes:
      - $PWD/splunk-uf1/:/opt/splunkforwarder/etc/apps/splunk-uf1/
    ports:
      - 3333:3333
      
  splunk_eventgen:
    image: guilhemmarchand/splunk-eventgen:latest
    container_name: splunk_eventgen
    restart: unless-stopped
    user: 'root'
    volumes:
      - $PWD/splunk-eventgen/:/opt/splunk-eventgen
    ports:
      - 6379:6379
      - 9500:9500
    depends_on:
      - splunk_uf1
    command: 'splunk_eventgen -v generate /opt/splunk-eventgen/default/eventgen.conf'

